{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0b6f2d3",
   "metadata": {},
   "source": [
    "PyTorch 공부하기전\n",
    "\n",
    "📌 1. PyTorch 소개\n",
    "PyTorch란 무엇인가?\n",
    "\n",
    "TensorFlow와의 차이점\n",
    "\n",
    "동적 계산 그래프의 이해\n",
    "\n",
    "\n",
    "\n",
    "📦 2. 설치 및 환경 설정\n",
    "bash\n",
    "복사\n",
    "편집\n",
    "# Conda\n",
    "conda install pytorch torchvision torchaudio cpuonly -c pytorch\n",
    "\n",
    "# Pip\n",
    "pip install torch torchvision torchaudio\n",
    "\n",
    "\n",
    "\n",
    "🧮 3. Tensor 기초\n",
    "Tensor 생성 (torch.tensor, torch.zeros, torch.ones, torch.randn)\n",
    "\n",
    "Tensor 차원 (shape), 인덱싱, 슬라이싱\n",
    "\n",
    "Tensor 연산 (덧셈, 곱셈, 행렬곱 등)\n",
    "\n",
    "Numpy와 상호 변환\n",
    "\n",
    "python\n",
    "복사\n",
    "편집\n",
    "import torch\n",
    "a = torch.tensor([[1, 2], [3, 4]])\n",
    "print(a.shape)\n",
    "\n",
    "\n",
    "\n",
    "⚙️ 4. Autograd (자동 미분)\n",
    "requires_grad의 역할\n",
    "\n",
    ".backward() 호출로 그래디언트 계산\n",
    "\n",
    ".grad를 통한 그래디언트 확인\n",
    "\n",
    "그래디언트 초기화 (.zero_())\n",
    "\n",
    "python\n",
    "복사\n",
    "편집\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = x**2\n",
    "y.backward()\n",
    "print(x.grad)  # 출력: tensor(4.) \n",
    "\n",
    "\n",
    "\n",
    "🏗 5. 모델 구성 (nn.Module)\n",
    "nn.Module 이해와 상속\n",
    "\n",
    "forward() 메서드 정의\n",
    "\n",
    "파라미터 확인 (model.parameters())\n",
    "\n",
    "모델 저장 및 불러오기 (torch.save, torch.load)\n",
    "\n",
    "python\n",
    "복사\n",
    "편집\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(10, 1)\n",
    "    def forward(self, x):\n",
    "        return self.fc(x) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "🔧 6. 손실 함수와 옵티마이저\n",
    "주요 손실 함수: nn.MSELoss, nn.CrossEntropyLoss\n",
    "\n",
    "옵티마이저: torch.optim.SGD, Adam, RMSprop\n",
    "\n",
    "학습 루프 구성\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "📂 7. 데이터 로딩 (DataLoader)\n",
    "Dataset 클래스 상속 및 커스터마이징\n",
    "\n",
    "DataLoader로 미니배치 구성\n",
    "\n",
    "셔플 및 배치 사이즈 설정\n",
    "\n",
    "python\n",
    "복사\n",
    "편집\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "dataset = MyDataset(torch.randn(100, 10))\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "🖼 8. GPU 사용하기\n",
    "cuda 장치 확인: torch.cuda.is_available()\n",
    "\n",
    "모델/텐서 .to(device) 사용\n",
    "\n",
    "python\n",
    "복사\n",
    "편집\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "🧪 9. 학습/평가 분리\n",
    "model.train() vs model.eval()\n",
    "\n",
    "with torch.no_grad(): 사용법\n",
    "\n",
    "Accuracy 및 기타 지표 계산\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "🧰 10. 실전 프로젝트 구성\n",
    "학습 로그: tensorboard, wandb\n",
    "\n",
    "모델 저장/불러오기\n",
    "\n",
    "하이퍼파라미터 튜닝\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "📚 추천 실습\n",
    "MNIST 숫자 분류\n",
    "\n",
    "CIFAR-10 이미지 분류\n",
    "\n",
    "텍스트 분류 (IMDB)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
